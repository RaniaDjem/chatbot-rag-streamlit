import streamlit as st
import sys
import tempfile
from utils import process_pdf, get_chain

# Ignore the torch module from being watched by Streamlit to avoid path issues (premier probleme solved)
sys.modules["torch.classes"] = None

st.set_page_config(page_title="Chatbot RAG PDF", page_icon="ğŸ§ ")

# ğŸ“ Introduction
st.title( "Chatbot Intelligent sur Document PDF")
st.markdown("""
Bienvenue sur **Chatbot PDF** ! 

TÃ©lÃ©versez simplement un fichier **PDF** (article, rapport, cours, etc.), et posez **toutes vos questions** dessus   
Notre assistant intelligent lit le document et vous rÃ©pond prÃ©cisÃ©ment, en s'appuyant sur le contenu du PDF.

_Câ€™est comme avoir un assistant personnel qui lit pour vous et vous rÃ©sume tout_ 
""")

# Fichier PDF
uploaded_file = st.file_uploader("Choisissez un fichier PDF", type="pdf")

if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
        tmp_file.write(uploaded_file.read())
        pdf_path = tmp_file.name

    st.success("Document chargÃ©. Initialisation en cours...")
    vectorstore = process_pdf(pdf_path)
    qa_chain = get_chain(vectorstore)

    st.success("Chatbot prÃªt ! Posez votre question.")
    question = st.text_input("Votre question :")

    if question:
        with st.spinner("GÃ©nÃ©ration de la rÃ©ponse..."):
            response = qa_chain.run(question)
            st.markdown(f"**RÃ©ponse :** {response}")

#  Stack technique & crÃ©dits

st.markdown("---")
st.markdown(
    "<div style='text-align: center;'>"
    "DÃ©veloppÃ© avec â¤ï¸ par ğŸ‘©â€ğŸ’» <strong>Rania Djema</strong><br>"
    "<small>Stack : Langchain Â· Mistral AI Â· HuggingFace Â· FAISS Â· Streamlit</small>"
    "</div>",
    unsafe_allow_html=True
)
